---
title: "Take-Home Exercise 1"
author: "Leonard Lee"
format:
  html:
    code-fold: true
    code-summary: "Show me the good stuff"
execute:
  warning: false
---

# Setting

City of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards. The local council of the city is in the process of preparing the Local Plan 2023. A sample survey of 1000 representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received.

# The Task

In this take-home exercise, you are required to apply the concepts and methods you had learned in Lesson 1-4 to reveal the demographic and financial characteristics of the city of Engagement byusing appropriate static and interactive statistical graphics methods. This exercise requires a user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns.

# The Data

For the purpose of this study, two data sets are provided. They are:

Participants.csv 
Financial.csv

# 1 Load Packages

```{r}
pacman::p_load(readr, ggrepel, patchwork, Hmisc, ggthemes, hrbrthemes, ggstatsplot, ggiraph, plotly, dplyr, patchwork, DT, tidyverse, ggplot2, stats, ggridges, viridis)
```

# 2 Import the Data

```{r}

Fdata <- read_csv("data/FinancialJournal.csv")
Jdata <- read_csv("data/Participants.csv")


```
# 3 Cleaning and Preparing the Data

## 3.1 Financial Dataset Summary

```{r}
Hmisc::describe(Fdata)

```

## 3.2 Joviality Dataset Summary

```{r}

Hmisc::describe(Jdata)
```

## 3.3 Correcting Demographic Data Format [Jdata]

::: {.callout-note collapse="true"}

- **_participantId_** is currently classified as <dbl> instead of nominal, and is cast to <chr> class using as.character().

- **_educationLevel_** is currently classified as <chr> categorical data, and is cast as factor type using the ordered() function, in accordance to its inherent hierarchy. 

- **_householdSize_** and **_interestGroup_** are classified as <dbl> and <chr> respectively despite being categorical in nature. The two variables are cast as factors using as.factor()

:::


```{r}
Jdata_new <- Jdata %>%
  #change PariticipantId to <chr>
  mutate(participantId = as.character(Jdata$participantId),
         
  #update educationaLevel with ordinal scale
  educationLevel = ordered(Jdata$educationLevel, levels = c("Graduate", "Bachelors", "HighSchoolOrCollege", "Low")),
  
  # Cast householdSize and interestGroup as factors
  householdSize = as.factor(Jdata$householdSize),
  interestGroup = as.factor(Jdata$interestGroup)
  )

```

## 3.4.1 Correcting Financial Data Format [Fdata]

::: {.callout-note collapse="true"}

- **_participantId_** is currently classified as <dbl> instead of nominal, and is cast to <chr> class using as.character().


- **_category_** is classified as <dbl>, and is cast as factor using as.factor()

:::

```{r}
Fdata_new <- Fdata %>%
  #change PariticipantId to <chr>
  mutate(participantId = as.character(Fdata$participantId),
         
  #Extract Year-Month from timestamp
  YMDate = paste0(year(timestamp), "-", sprintf("%02d", month(timestamp))),
         
  # Cast householdSize and interestGroup as factors
  category = as.factor(Fdata$category),
  
  # Round amount to 2dp
  amount = as.integer(round(amount, digits = 2))
  ) %>%
  
  # remove original timestamp column
  select(-timestamp) %>%
  
  #sort by ParticipantId
  arrange(participantId)
  
```

## 3.4.2 Pivoting Financial Data [Fdata_new]

```{r}

Pivot_Fdata <- Fdata_new %>%
               #Define row groups
               group_by(participantId, YMDate) %>%
  
               # Sum total amount per category for each month
               summarise(Education = sum(amount[category == "Education"]),
                         Food = sum(amount[category == "Food"]),
                         Shelter = sum(amount[category == "Shelter"]),
                         Recreation = sum(amount[category == "Recreation"]),
                         RentAdjmt = sum(amount[category == "RentAdjustment"]),
                         Wage = sum(amount[category == "Wage"])) %>%
                ungroup()
  
head(Pivot_Fdata, n = 3)
```

# 4 Data Preparation

```{r}
Pivot_Fdata <- Pivot_Fdata %>%
               #create new column with financial outflow (expenses)
               mutate(Total_Expense = Education + Food + Shelter + Recreation) %>%
               #calculate proportion of expense wrt wage
               mutate (Expense_Prop = (abs(Total_Expense)/Wage)*100)


Pivot_Avg_Fdata <- Pivot_Fdata %>%
               # Group by Participant ID to get average values
               group_by(participantId) %>%
               summarise(NumT = n(),
                         Education = (sum(Education)/NumT),
                         Food = (sum(Food)/NumT),
                         Shelter = (sum(Shelter)/NumT),
                         Recreation = (sum(Recreation)/NumT),
                         RentAdjmt = (sum(RentAdjmt)/NumT),
                         Wage = (sum(Wage)/NumT),
                         Total_Expense = (sum(Total_Expense)/NumT),
                         Expense_Prop = (sum(Expense_Prop)/NumT))
               

Joined_data <- merge(Pivot_Avg_Fdata, Jdata_new, by = "participantId") %>%
               select(unique(colnames(.))) %>%
               arrange(as.numeric(participantId))

head(Joined_data, n= 3)
```
## 4.1 Establishing Demographic Data Groups


### 4.1.1 Age Groups

Through a dotplot, we see that age distribution across the participants is spread between 18 to 60, with minor fluctuations.

```{r}
# Computing min and max age to annotate plot
min_age <- min(Joined_data$age)
max_age <- max(Joined_data$age)


dem_age <- ggplot(Joined_data, aes(x = age)) +
  geom_dotplot(binwidth = 1,
               stackratio = 1.2,
               stackdir = "up",
               fill = "#00BF7D", #< Fill colour same as bar charts
               color = NA,
               dotsize = 0.6) +
  labs(title = "Age",
       x = NULL,
       y = NULL)

dem_age2 <-dem_age + 
            annotate(geom = "text", x = min_age, y = 0.83,
            label = paste0("Youngest:\n", min_age)) + #< add text annotation to show age range
            annotate(geom = "text", x = max_age, y = 0.83,
            label = paste0("Oldest:\n", max_age)) +
            theme(axis.text.y = element_blank(), #< remove unnecessary elements from plot
            panel.grid.major = element_blank())
dem_age2

```


::: {.cushbox .cushicon}

Participants are further grouped by age into **four categories**, each encompassing approximately 10 years of age range:

**18-29, 30-39, 40-49, 50-60** 

:::




## Grouping Participants by Age
::: panel-tabset
### Code
```{r}
Joined_data$ageGroup <- as.factor(cut(Joined_data$age,
                                        breaks = c(0,29,39,49,60),
                                        labels = c("18-29", "30-39", "40-49", "50-60")))

```
### Distribution Barchart

```{r}

# Barchart of ageGroup
dem_agegrp<- ggplot(Joined_data, aes(x = ageGroup)) +
            geom_bar() +
            labs(title = "Even Distribution of Participants across Age Groups", #< Linebreak added to title so it does not get truncated
                  x = "Age Group",
                  y = NULL) +
            geom_text(stat = "count",
                      aes(label = after_stat(count)),
                      vjust = -1) +
            ylim(0,400) + #< Same y-axis limits for both age and wage plots to standardise
            theme(text = element_text(size = 12))

dem_agegrp
```
:::
## 5 Exploratory Data Analysis

### 5.1 Joviality

The survey returned a range of Joviality scores between 0 and 1, and it is assumed that 1 is the maximum score to which one is most Jovial (or happy), and 0 is conversely the minimum score to which indicates the lowest possible state of happiness.

### Normality Testing and Distribution

::: panel-tabset



## QQ Plot
```{r}
set.seed(1234)
qqnorm(Joined_data$joviality)
qqline(Joined_data$joviality)

```

The qqplot compares the distribution of the data against the expected normal distribution. As the points deviate significantly from the line, the qqplot suggests that the data is not normally distributed.

## Shapiro-Wilk Test

```{r}
shapiro.test(Joined_data$joviality)


```

The Shapiro-Wilk test is a widely used method to test for normality. As p < 0.05, there is sufficient statistical power to reject the null hypothesis that the data is normally distributed.


## Distribution

```{r}
mean_j <- mean(Joined_data$joviality)
med_j <- median(Joined_data$joviality)
std_j <- sd(Joined_data$joviality)

ggplot(Joined_data, aes(x = joviality)) + 
      geom_histogram(aes(y = ..density..),
                    binwidth = 0.05, 
                    fill = "#CCFF99",
                    color = "grey") +
      stat_function(fun = dnorm,
                args = list(mean = mean_j,
                            sd = std_j),
                col = "skyblue",
                linewidth = 1) +
      geom_vline(aes(xintercept = mean_j),
                colour="#4d5887", linewidth = 0.8, linetype = "dashed") +
      annotate(geom = "text", x = mean_j + 0.12, y = 1.4,
                  label = paste0("Mean Joviality: ", round((mean_j),2)),
                  color = "#4d5887") +
      geom_vline(aes(xintercept = med_j),
                colour="grey20", linewidth = 0.8, linetype = "dashed") +
      annotate(geom = "text", x = med_j - 0.13, y = 1.5,
                  label = paste0("Median Joviality: ", round((med_j),2)),
                  color = "grey20") +
      scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
      labs(title = "Distribution of Participants' Joviality Scores") +
      theme(axis.text.y = element_blank(),
            axis.title.y = element_blank(),
            panel.grid.major = element_blank())

```
:::



## 5.2 Wage (Income)

### Normality Testing

::: panel-tabset

## QQ Plot
```{r}
set.seed(1234)
qqnorm(Joined_data$Wage)
qqline(Joined_data$Wage)

```

The qqplot compares the distribution of the data against the expected normal distribution. As the points deviate significantly from the line, the qqplot suggests that the data is not normally distributed.

## Shapiro-Wilk Test

```{r}
shapiro.test(Joined_data$Wage)


```

The Shapiro-Wilk test is a widely used method to test for normality. As p < 0.05, there is sufficient statistical power to reject the null hypothesis that the data is normally distributed.

:::

### Cut Wage into Categories based on quantiles


```{r}
describe(Joined_data$Wage) #to assess best cut points for income levels

```
::: {.cushbox .cushicon}

Based on the distribution described above, the cut points values matching **25th, 50th and 90th percentile** are used to group participants by income level:

**Bottom 25th Percentile -> Low Income**
**26th to 50th Percentile -> Low-Middle Income**
**50th to 90th Percentile -> Middle-High Income**
**Top 10th Percentile -> High Income**

:::

## Grouping Participants by Income Levels

::: panel-tabset
### Code
```{r}

# Define the breaks for the three bins
breaks <- c(0, 2551, 3388, 6574, Inf)

# Bin the Wage variable into three categories using cut()
income_levels <- cut(Joined_data$Wage, breaks, labels = c("Low", "Low-Middle", "Middle-High", "High"))

# Add the income levels as a new column in the dataset
Joined_data$Income_Level <- income_levels
```

### Distribution Barchart

```{r}
# Barchart of Income Level
dem_incomelvl<- ggplot(Joined_data, aes(x = Income_Level)) +
            geom_bar() +
            labs(title = "High Distribution of \nParticipants in Middle-High Income Level", #< Linebreak added 
                  x = "Income Level",
                  y = NULL) +
            geom_text(stat = "count",
                      aes(label = after_stat(count)),
                      vjust = -1) +
            ylim(0,500) + 
            theme(text = element_text(size = 12))

dem_incomelvl
```
:::

 ## Association Testing (Chi-Squared Test)

::: panel-tabset

### Summary
```{r}



```

### Income Levels



### Education Levels


### Age Group
:::


### Comparison of mean Joviality Scores

::: panel-tabset

## Income Levels

```{r}
ggbetweenstats(Joined_data, x= Income_Level, y= joviality) +
  labs(x = "Income Level", y = "Joviality Score")

```
As p is less than 0.05, we reject the null hypothesis that there is no significant difference in means across income groups.



## Age Groups

```{r}

ggbetweenstats(Joined_data, x= ageGroup, y= joviality) +
  labs(x = "Age Group", y = "Joviality Score")

```


An interesting insight can be gleaned from this comparison of means- as a significantly higher mean joviality score is observed in both Middle and Lower income groups, while the lowest mean score is observed in the High income group. 


## Education Levels

```{r}
ggbetweenstats(Joined_data, x= educationLevel, y= joviality) +
  labs(x = "Education Level", y = "Joviality Score")

```

Through comparison of mean joviality scores across education levels, the null hypothesis is that there is no difference between means. As p > 0.05, we accept the null hypothesis.

## Household Size

```{r}
ggbetweenstats(Joined_data, x= householdSize, y= joviality) +
  labs(x = "Household Size", y = "Joviality Score")

```
## Interest Groups

```{r}


ggbetweenstats(Joined_data, x = interestGroup, y = joviality) +
  scale_color_manual(values = viridis(length(levels(Joined_data$interestGroup)))) +
  labs(x = "Interest Group", y = "Joviality Score")



```


:::

::: {.bubblebox .bubbleicon}
**Insights**

1) An interesting insight can be gleaned from this comparison of means- as a significantly higher mean joviality score is observed in both Middle and Lower income groups, while the lowest mean score is observed in the High income group. 

2) 

3)

:::


### 
```{r}
# prepare the data
Joined_data$education_group <- factor(Joined_data$educationLevel, 
                                 levels = c("Low", "HighSchoolOrCollege", "Bachelors", "Graduate"), 
                                 labels = c("Low education", "High School or College", "Bachelor's Degree", "Graduate Degree"))


# create the ggplot object

p <- ggplot(Joined_data, aes(x = Wage, fill = education_group)) +
  geom_density(alpha = 0.6) +
  labs(x = "Wage ($)") +
  labs(title = 'Wage Distribution across Education Levels', fill = 'Education Level') +
  theme(axis.text.y = element_blank(), axis.title.y = element_blank())



# convert to interactive plot
ggplotly(p)

```

```{r}
p2 <- ggplot(Joined_data, aes(y = education_group, x = Wage, fill = education_group)) +
  geom_density_ridges(alpha = 0.6, scale = 0.9) +
  scale_x_continuous(limits = c(0, 20000)) +
  labs(x = "Wage ($)", y = "", fill = 'Education Level') +
  labs(title = 'Wage Distribution across Education Levels') +
  theme(axis.text.y = element_blank(), axis.title.y = element_blank())

p2
```

```{r}



```

### Expense and Joviality (Build more cost efficient stuff)



### Age and Joviality (Need more ageing popn stuff?)

### Interest Group X Joviality (IG related stuff)

### Wage x Kids X Joviality 

### Kids and Joviality (Kids related facilities)

## Wage and Joviality

::: {.callout-note collapse="true"}
:::

::: panel-tabset
### Header

## 

## 
:::
